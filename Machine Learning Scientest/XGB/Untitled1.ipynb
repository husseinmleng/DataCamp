{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971af6d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Derived' object has no attribute 'i'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6987/512768544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6987/512768544.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDerived\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Derived' object has no attribute 'i'"
     ]
    }
   ],
   "source": [
    "class Base:\n",
    "    def __init__(self, i = 0):\n",
    "        self.i = i\n",
    "    \n",
    "class Derived(Base):\n",
    "    def __init__(self, j = 0):\n",
    "        self.j = j\n",
    "\n",
    "def main():\n",
    "    d = Derived()\n",
    "    print(d.i)\n",
    "    print(d.j)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba21546b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'churn_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6987/816528061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create arrays for the features and the target: X, y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchurn_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchurn_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create the training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'churn_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the classifier: dt_clf_4\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "dt_clf_4.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred_4\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the predictions: accuracy\n",
    "accuracy = float(np.sum(y_pred_4==y_test))/y_test.shape[0]\n",
    "print(\"accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(X,y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params \n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of number of boosting rounds\n",
    "num_rounds = [5, 10, 15]\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n",
    "\n",
    "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_rounds:\n",
    "\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
    "print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation with early stopping: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,nfold=3,\n",
    "seed=123,early_stopping_rounds=10,num_boost_round=50,metrics=\"rmse\",as_pandas=True)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa508847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree (boosting round)\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the eta \n",
    "for curr_val in eta_vals:\n",
    "\n",
    "    params[\"eta\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,nfold=3,\n",
    "seed=123,early_stopping_rounds=5,num_boost_round=10,metrics=\"rmse\",as_pandas=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6043d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\":\"reg:linear\"}\n",
    "\n",
    "# Create list of max_depth values\n",
    "max_depths = [2,5,10,20]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the max_depth\n",
    "for curr_val in max_depths:\n",
    "\n",
    "    params[\"max_depth\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,nfold=2,\n",
    "seed=123,early_stopping_rounds=5,num_boost_round=10,metrics=\"rmse\",as_pandas=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params={\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create list of hyperparameter values: colsample_bytree_vals\n",
    "colsample_bytree_vals = [0.1,0.5,0.8,1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the hyperparameter value \n",
    "for curr_val in colsample_bytree_vals:\n",
    "\n",
    "    params[\"colsample_bytree\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(param_grid=gbm_param_grid,estimator=gbm,scoring = \"neg_mean_squared_error\",cv=4,verbose=1)\n",
    "\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(X,y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == object)\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b74ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(categorical_features=categorical_mask,sparse=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
    "df_encoded = ohe.fit_transform(df)\n",
    "\n",
    "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
    "print(df_encoded[:5, :])\n",
    "\n",
    "# Print the shape of the original DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Print the shape of the transformed array\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9359284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert df into a dictionary: df_dict\n",
    "df_dict = df.to_dict(\"records\")\n",
    "\n",
    "# Create the DictVectorizer object: dv\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Apply dv on df: df_encoded\n",
    "df_encoded = dv.fit_transform(df_dict)\n",
    "\n",
    "# Print the resulting first five rows\n",
    "print(df_encoded[:5,:])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(dv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29102a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7d596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ebbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a41101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d5379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
